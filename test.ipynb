{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The capital of France is Paris! üá´üá∑‚ú® It's known for its rich history, art, fashion, and, of course, the iconic Eiffel Tower. If you ever get the chance to visit, it's a city full of wonders! üóº‚ù§Ô∏è\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from promptflow.core import Prompty\n",
    "from promptflow.core import AzureOpenAIModelConfiguration\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if \"AZURE_OPENAI_API_KEY\" not in os.environ:\n",
    "    # load environment variables from .env file\n",
    "    load_dotenv('.env')\n",
    "\n",
    "f = Prompty.load(source=\"chat.prompty\")\n",
    "\n",
    "# execute the flow as function\n",
    "result = f(question=\"What is the capital of France?\")  \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from pydub import AudioSegment\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
    "from pytubefix import YouTube\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    ")\n",
    "\n",
    "# Utility functions for caching and sanitizing filenames (same as before)\n",
    "def load_cache(cache_file):\n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def save_cache(cache_file, data):\n",
    "    with open(cache_file, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    base_name, ext = os.path.splitext(filename)\n",
    "    base_name = re.sub(r'[^\\w\\s-]', '', base_name)\n",
    "    base_name = base_name.replace(' ', '_')\n",
    "    base_name = base_name[:255]\n",
    "    sanitized_filename = base_name + ext\n",
    "    return sanitized_filename\n",
    "\n",
    "def transcribe_audio(audio_path, client, chunk_size_ms=60000):  # Chunk size set to 1 minute\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    total_duration_ms = len(audio)\n",
    "    transcription_text = \"\"\n",
    "    \n",
    "    # Process in chunks\n",
    "    for start in range(0, total_duration_ms, chunk_size_ms):\n",
    "        end = min(start + chunk_size_ms, total_duration_ms)\n",
    "        chunk = audio[start:end]\n",
    "        chunk_path = audio_path + f\"_{start}_{end}.mp3\"\n",
    "        chunk.export(chunk_path, format=\"mp3\")\n",
    "\n",
    "        # Transcribe chunk\n",
    "        with open(chunk_path, \"rb\") as f:\n",
    "            response = client.audio.transcriptions.create(\n",
    "                model=\"whisper\",\n",
    "                file=f,\n",
    "            )\n",
    "            transcription_text += response.text + \" \"\n",
    "        os.remove(chunk_path)  # Clean up chunk file\n",
    "    return transcription_text\n",
    "\n",
    "def fetch_transcript(video_id):\n",
    "    \"\"\"\n",
    "    Attempt to fetch the transcript using YouTubeTranscriptApi.\n",
    "    If it fails, fall back to audio download and transcription.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to fetch the transcript\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        # Combine all the transcript parts into one string\n",
    "        full_text = \" \".join([item['text'] for item in transcript])\n",
    "        print(\"Transcript fetched successfully!\")\n",
    "        return full_text\n",
    "    except TranscriptsDisabled:\n",
    "        print(\"Transcripts are disabled for this video. Falling back to audio transcription.\")\n",
    "        return transcribe_audio_fallback(video_id)\n",
    "    except NoTranscriptFound:\n",
    "        print(\"No transcript found for this video. Falling back to audio transcription.\")\n",
    "        return transcribe_audio_fallback(video_id)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def download_audio(video_id, output_path=\"audio.mp4\"):\n",
    "    \"\"\"\n",
    "    Download the audio of the YouTube video using pytube.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "        yt = YouTube(video_url)\n",
    "        stream = yt.streams.filter(only_audio=True).first()\n",
    "        stream.download(filename=output_path)\n",
    "        print(f\"Audio downloaded successfully: {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download audio: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_audio_fallback(video_id):\n",
    "    \"\"\"\n",
    "    Download audio and transcribe it using Whisper as a fallback.\n",
    "    \"\"\"\n",
    "    audio_path = download_audio(video_id)\n",
    "    if not audio_path:\n",
    "        return \"Failed to download audio for transcription.\"\n",
    "\n",
    "    try:\n",
    "        # Load the Whisper model\n",
    "        result = transcribe_audio(audio_path, client)\n",
    "        print(\"Audio transcription completed successfully!\")\n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to transcribe audio: {e}\")\n",
    "        return \"Transcription failed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript fetched successfully!\n",
      "\n",
      "Final Transcript:\n",
      " [Music] all right welcome to another video so today we are going to be talking about promp flow and we're going to get you started with prompt flow and be able to deploy your own prompt flow inside of azure machine learning this is kind of what the ending is going to look like so you're actually going to have a flow that you can work with and manipulate you'll be able to chat with it interactively in the console uh you'll be able to deploy this to an online endpoint which in the end is going to look something like this to where we actually in aure machine learning will have an online endpoint with all the code that you have put together uh and deployed to a container instance uh kubernetes container uh that you have the ability to do auto scaling and even do monitoring of that if you so want to uh keep in mind that when this is deployed it not only it is just your code that makes the prompt flow work it does not include the open AI model so when you make a call to open AI you're still going to be incurring charges for each thousand tokens that you actually uh hit and you'll be able to interact with it as an online endpoint if you want to test it plus you'll be able to get a scoring URL you can hand off to a developer so if you want to ask a question of the uh open AI you can actually run it through the scoring mechanism with the key and you get sample code for python for C and for R so to get us started on this this is what you're going to need and aure subscription and we're going to walk through all of this I'm going to assume you already have an Azure subscription and you already have GPT 3.5 or gp4 access but we're going to create a resource Group go ahead and create the services for gp35 uh cognitive Service uh search also known as Azure Azure AI search now uh or Azure AI document intelligence depending on which document you look at Azure machine learning service and inside of an Azure machine learning service we're actually going to also create a compute so with that let's go ahead and get started all right so here we go we're going to start off as we are now in the Azure machine learning portal first thing we're going to do is create a resource I want to create a resource Group and we should get some results for Resource Group see what comes back Resource Group create we are going to call this uh RG CU I call all my resource groups they start with RG p r o m PT prompt we're going to put this in Us East and next we're going to skip on the tags we're going to make sure that we validation our validation passes and do a create this will take about a split second to create so once we have the resource Group now we need to start putting our services in here so the service that we're going to be doing are going to be and I'm going to search first for cognitive search it has been renamed to document intelligence or AI search uh so we're going to go here uh select Azure AI search and click create and it's going to ask us a few questions and we're going to put this one in East us also so make sure I get that right on each one of these because I want to make sure everything lives in the same region uh this one I'm just going to call it uh search see lowercase letters always sh search sh we're going to call it that so we can find it we're going to keep the pricing tier standard uh right now so we don't have to we're only going to create one index in this for the purpose of the demo uh keep in mind for each of the services you do create some of them will incur costs uh even when you're not using them so be cognizant of that so if you wanted to do this as just a demo or a lab you could actually just follow these instructions run all this in one day and then delete everything at the end of the day so we're going to go ahead and create that that's going to take a couple minutes for it to create and I'll jump the video ahead uh when we get to that point so you can actually watch it as we go through and when this is complete we're going to create another service all right so our resources deployed so now we can actually go to RG prompt back to our Resource Group and see that we have a cognitive search out here now so now I'm going to go here and just do a create in the resource Group because we also need to deploy in Azure machine learning instance so we'll look for that and do a create Azure machine learning and we're going to put in in our Resource Group uh name of it I'm going to call this AML D prompt I don't think I've used that one uh we're going to put this in East us with our other resources and we're going to let just take the defaults on the storage account the key VA and the application insights and container registry we're not going to worry about that uh for networking I'm going to go a and keep it as public identity uh let's see encryption we're going to use Microsoft manage Keys identity just go and keep the defaults no tags for this one let it pass validation and then we can actually create our resource this one actually runs pretty quickly because what it's really doing is just creating a place where this lives and once we get this set up we'll actually have an Azure machine learning um resource created and then we'll go into AML after that into the Azure machine learning workspace we'll show that in just a minute we'll see how long this takes I may have to speed this up uh when we get ready to edit the video all right through the magic of video editing our resources complete so now we can go back to our Resource Group and now we'll see that we have quite a few more services out here that AZ your machine learning created as well as our search shop so we still need one more resource that we need to create which is open AI uh if you have open AI in a different Resource Group you could probably use that but I'm going to go ahead and create it in here uh obviously if you've got multiple people using open AI uh with multiple products you may have to uh think about that in this case I'm going to call it o AI oh what should I call it uh open AI GPT give it a nice boring name pricing tier standard zero uh subdomain is already in use go figure open AI all right let's change this to open AI ship that's probably not in use uh nope we can use that one so we're going to go next uh network is going to be public all networks uh tags no tags running validation make sure everything's good now we can do a create uh and this will create pretty quickly also so you won't have to wait for very long but those are all the services that we're going to need to get started so we can get into uh prompt flow so let's see if this goes by pretty quickly and we'll go to our Resource Group and go ahead and get started all right our Resource Group is uh populated with lots of services now which is what we wanted now the first thing we're going to need to do and let me make the screen a a little bit larger for you first thing we're going to need to do is go into our Azure openai resource and go to model deployments uh the reason we need to do this is because we're going to have to add uh we're going to have to add some U open AI deployment some models out here so that we have them available I want to use today I'm going to use GPT 35 turbo 16k and we're going to give the deployment name the exact same name as the model so I don't get confused later and all you have to do is create and it will create it now we need one more out here also and that's the Ada embedding model because we're going to need that also because that's going to translate our data into a vector embedding so we can search it against a vector database so we're going to call that the same thing so I can figure it out later and remember what it is now after you create these even though they show up in the console immediately it takes about two or 3 minutes before you can actually go in and access one of these so if you wanted to chat with us right now you might have to wait just a a little bit of time so if I were to type in hello it's like the API is not ready yet that takes a couple minutes minutes and that's okay just be prepared for that so it's not that big of a deal so what we're going to do now is go back to the Azure portal and go to our new Resource Group RG prompt uh we've got our oi uh shf set up and we are going to have to come back here in a little while and get this uh endpoint and one of these keys but we'll actually do that in a few seconds I'll go ahead and leave this up and we'll come back to it in a minute let's go back to the Azure portal uh let's go to the resource Group we just created with all our fresh new services in there and now we're going to go into the Azure machine learning this is going to take us to the AML studio uh which is where we're going to be doing all of our work today so I'll make this a little bit bigger but what we're going to be doing is uh going into prompt flow creating a new prompt and we're going to choose one of these actually the one we're going to choose is a multi-round Q&A on your data but before we get to that we need to create a compute instance so we're going to go down here to uh our compute under manage and we're going to create a new compute instance so right now easy to do just click on new and you're going to see what you have have quota for out here and it'll tell you how much quota you have for each one of these uh I'm going to create uh this one cost these two cost about 29 cents an hour this one's the same price and I get more memory so I'm going to click on the uh E4 DS and you can choose any one you want I'm going to set this to shut down after 120 Minutes of inactivity so uh you can also add a schedule if you wanted to so I could change this to East Coast time which I do this on all my compute instances anyway because just in case I go off and forget I don't have to worry about it and we'll say that every day at 800 p.m. if this instance is still running just shut it down uh so we're going to set that right there click on next I'm not going to worry about security and not going to add any other applications not going to worry about any tags and then you go to the review screen uh now you can do a create now this will take a couple minutes to create anywhere from 1 to 5 minutes I've had really good luck with it lately that I can typically get a compute instance created in about 5 minutes or less so when this is uh we'll come back and check on this in a few minutes in the meantime we actually have have to go into our promp flow because to get started we need to worry about some of the tabs we have out here connections runtime and Vector index connections give Azure machine learning access to your other products that you have in your resource Group so the first thing we're going to do is go ahead and set up Azure open AI so in this case I'm just going to call it open AI so it'll be super simple for me to figure it out providers Azure open AI uh then we're going to select my subscription uh we're going to select the names of what I created the Azure open app I and the one I created most recently was the oi ship so we're going to select that one now we need to go back and get that API key that we had talked about so we're going to go back to here to where I had oi sh and we're going to grab that uh first key paste it into here and anytime you can pause these videos if I'm moving too fast I've done this a few times already so I'm getting better at it uh that's the nice thing about video if you get stuck or somewhere you need to research something you can pause it anytime and in this case we're going to go ahead and leave the API type is azure which it is and the API version we're going to leave as preview and that may change over time too so don't be surprised so that's our first connection and we need that connection because for prompt flow to be able to access our open AI we need to have this connection set up so the next one we're going to do is cognitive search okay so in this case I'm going to call it uh search same thing I called the other service ship so I can easily identify it uh cognitive search then we're going to go to the API key for cognitive search so we're going to go back here and back out to our Resource Group go to search ship which is our cognitive search service we're going to go to security which is down here or settings actually it's under keys and we'll see that we have a primary and secondary key so I can grab that key go ahead and pass that in there the next thing we're going to need is the API base now the API base is not in the same place where the keys are the API base is under overview so what we're going to do is copy that out of the URL up here that's my API base right there under your uh URL now we're going to paste that API base for our cognitive search there and we're going to go ahead and save that so now we have the two main things we need now there may be a a circumstance where if you ever wanted to create a uh Azure content safety you could actually go in because content safety is a service that exists in Azure so you would have to add that to your resource Group also we're not going to do that today because I'm using Azure open AI which comes with its own content safety there's no point in doing it twice uh so we don't need to worry about anything more than that now we can check on our compute cuz the next thing we need to do we'll see our computes up and running so we're going to go back to promp flow now and we're going to add a runtime cuz our promp flow needs a machine that it can run on so what we're going to do is give it a name uh let's go ahead and search for what we have down here we'll see that we have one running already so I'm going to call just grab that same name because it's going to show up in my prompt flow as the same name so I don't get it confused with anything else either and just create that first thing it's going to do is autor restart compute instance all right so we're going to say confirm because if you don't do that uh prompt won't be able to use it so we're going to confirm this this takes about 3 or 4 minutes for it to restart the compute instance cuz it's going to add some security and software that it's going to install on there for us to make it prop flow friendly so this takes some time to run and you'll see that it's not available right now uh when we're done with that the next thing we're going to do is come in and create our Vector index so we're going to pause the video wait for the compute to create then we're going to go ahead and get started with creating our Vector index and jump right into all right now we got our compute running as you can see out here it's all ready to go so if I refresh I show that I've got my machine all set up uh gives me the size and we also know that if I drill into it I can actually see if I've got a schedule should show the schedule on here somewhere actually schedule's on the other one this is just a runtime that we have created CU we're back because we've got our uh connections created so far our open Ai and our cognitive search we've got our runtime created uh the next thing that we're actually going to do is create our Vector index now I like the fact you can do this because this makes it a little bit easier the reason we're creating a vector index is cu once again just like the other videos we did we're doing a r pattern a retrieval augmented generation which means I want to load some data from PDFs and it's actually going to be our uh standard HR docs our make believe human resource docs uh that we can go through and now what we can do is this is going to ask you the name of this and I'm just going to call it HR docs uh and I'm going to pull this up from my machine so I've actually got some folders out here already I've got a folder out here already with my roll Library my employee handbooks perks Plus North Wind standard benefits Northwind Health Plus benefits and our benefit options and I'm going to upload those and it's going to say are you sure you want to do that I'm like absolutely so it comes up and tells us here's the list of all the things you you have uh all the ones you want to upload and you can notice that you have quite a few file types available to you so even if you have PowerPoints or Word documents or even python files you could upload those as well uh Vector store where we've actually we're going to use the Azure AI search index and this is the cognitive search because it found it from the connections so it knows it's out here so now we can click on next uh choose the connection type we're going to use open AI which that came from our connections also and then it's going to say what do you want to use for compute so in my CL case I want to use a compute cluster let's see where those things live I'm going to use the compute cluster I already created because I don't want to create another compute instance so I'm going to select compute instance down here and go ahead and choose the one that's already running and then I'm going to click on next and it's going to give us kind of a rundown of what it's actually doing then it's going to create the index now what this is going to do is create an Azure machine learning pipeline that will actually go out read those docs chunk them and then come back and give us the ability to get them in the index so we can search them at a later time and if you click on job details which you're going to see out here is an Azure machine learning pipeline running under jobs where you can actually see uh all of this come together and you can minimize it a little bit so you can take out now this takes about 10 minutes to run so we're going to stop the video again let this finish and then we're going to come back to it okay all right we've got our job complete now we can see that uh the Azure uh pipeline has completed all the steps are done so now what we can do is go ahead and close this go back to this and we'll go if we look at the vector index we'll see that we now have a vector index called HR docs we can look at the job details which will take us back to job so we can see the pipeline uh then we can actually look at the index data uh we're going to need to I'm going to leave this page open because we're going to need this data store URI in a few minutes if you don't know where this lives it can be really confusing to find because the documentation actually tells you how to build this manually uh which can be a little bit of a pain so I'm going to leave that up go back to here go to uh prompt flow once again and now I'm going to create my prompt flow so in this case what I want to do is take this multi-round Q&A so this is going to take and give us the ability to uh we're going to do this as uh chat HR docks so we're going to clone that takes a minute for it to to clone uh not too long but what this is going to give us it's going to go ahead and pre-populate everything for us so we don't have to worry about doing anything uh we've got all of our options up here we'll see that our compute run time's already been selected because for this to run we actually going to have to do this now we have some work we need to do and I can't remember all of it but I know first thing we have to do is modify query with history so it's going to ask you some questions like you know which uh where's your open AI connection and we set that up when we did the run times earlier so it knows that for the deployment name we're going to use GPT uh turbos 16k so it's good with that it knows that we need to have the open AI uh and then it's going to give it some uh history about you know given the following conversation user next question rephrase the question so it's going to give it some instructions and you have the ability to modify this all you want if you want to but there is one place where we're going to need to make a change now for the embed the question this is going to be the embedding model that's why we actually needed to have the text embedding so what it's going to do is take the text embedding uh here and take it and convert it into a Vector uh so that we can actually come back out and figure out you know what we wanted to do uh to search the index make sure we got that right GPT turbo Turbo embed the question inputs we closed that that's why I didn't see it uh now we've got this other one now by default this thing actually comes with the uh rag sample index and if we go look at that we open it up we'll see that there it's pointing to uh a demo uh basically index that we don't want to use that's where we're going to come back here and I want to grab this URI uh right here and I'm going to pass that in and replace this and it's kind of a long gnarly uh index but that's what we actually need to to get this set up and we'll see if this actually works and one thing you can do to test it uh get out of the way here go back to inputs and just run that and see if it has access to the index we'll see if it does or not if it doesn't have access I'll probably have to pause the video and do a little bit of work on it and I'll come back and tell you what I did but you can run this one cell by itself just to make sure I can get a connection to this and it ran completed so that's great uh let's see what else we need to change down here uh this is the generate python uh prompt text and you can see it's got some code in here and the neat thing about being able to integrate all this with h python is the fact that you can change these to where if you don't want to uh search for the question from an index what you could do is gut this module replace it with a python module and have it make a query to a SQL Server so that's kind of awesome now we are going to make some changes because this is our system prompt right here you are an AI system designed to answer questions uh from and form and source citation so we're going to make some changes to this uh and I'm going to copy it out I've already got it written so you don't we don't have to worry about me writing spending 10 minutes writing this so what I'm going to do is paste the my in there my uh my prompt in here because we're telling it that it's basically much like the other two demos I did the other two videos that you answer questions related to Koso Electronics employee handbook perks plus and Northwind Healthcare H healthc care uh it's pretty good with spelling thank goodness uh cancel I don't want to get away from this window you'll be given context and chat history and ask a question based on context and if the question is asked does not relate to the topic please respond with I am a Koso electronics company assistant I can help you with HR or Northwind health questions so that way we can try and prevent a little bit of jailbreak uh we can validate parse the input uh make sure that's going to work okay validation passed so I didn't make any errors and now if I got everything correctly I should be able to save this here and if I'm lucky let's see what happens let's do a chat and see what happens uh so this has got some preloaded chat that I'm not going to worry about so I'm going to start a new chat session once this actually gets saved and starts running and what it's going to do is we close that uh we'll see that it actually had some other stuff out here uh from the demo that was created uh what is my favorite question included in perks let's see if this works cuz I haven't tested this you just saw me set the whole thing up so we don't even know if it's going to work aha empty connection with chat context so what did I miss here aha chat context so we need a open AI connection deployment name it'll pick the deployment that it needs whether it's an embedding model or an open AI model and we've got topic presence penalty temperature is zero so be very strict now we're going to save that and and let's do the chat anyway so we'll close that and ask the question again and it's saving it on for us anyway and while this is running if you were to go look you can actually see that it tells you where in the prompt it is when it's actually running through this so if there's an error it'll pop up here let's wait for that to complete and we can open the chat back up ah so here we go what's included in perks plus perks plus covers a wide range of Fitness activities so we got to get answer and it gave us where if we have access to that PDF that we can go find it uh what what is the difference between healthc care plans just to trip it up a little bit uh see if we can't Health P plans let's see if what it says about that CU we're going to try a Jailbreak in here also I'm not going to try very hard at the jailbreak CU I don't have the jailbreak actually there is a service that manages that for us I don't have that set up but uh I want to see what it does if I ask it like who is Harry Potter because it's not supposed to answer that question ah so it didn't come back with an answer for that one so that's kind of what we would get uh let's see if we can't what is the difference between Northwind healthcare plans let's see if we can get some information because sometimes you need to give it more context and that's not uncommon in the other demos I've done for the videos you've probably seen me do something similar where sometimes you have to give it more context to be able to answer a question uh see if it comes back and tells us anything it's kind of a hard question because we're asking it to compare uh two different Health Plans uh so and then it comes back and gives us basically northw Health Plus northw house offers two plans northw Health Plus and Northwind standard and it gives us where we can find the benefit options and if we wanted to go look that up now the most important question who is Harry Potter let's see if it'll answer that one and this is basically an attempt it's not an attempt at a jailbreak but we're answering asking it a question it should not answer for us so that's kind of what I'm after right here because we gave it instructions in the prompt engineering not to answer anything unrelated to the documents that we have access to I am a Koso electronics company assistant can I help you with a a Koso or Northwind Health question awesome all right so that's already been saved we really don't need to save it again what we can do now is actually deploy this so we're going to give it that crazy name uh we're going to set this up on relatively uh kind of a large server I'm going to change the instance count to one sometimes it won't let you do that in Azure machine learning it gets angry if you drop the instance count but if you're doing a development inpoint you may want to uh you may want to do that so we're going to go and take all the defaults uh next uh and it's going to tell it you know where we're actually getting information from which means that this will reach out to Azure open aai when it runs and we're going to go ahead and create that uh so this takes a few minutes for it to create and what it will do is it'll show up as an endpoint down here so you can monitor it once this actually gets started uh it's in progress look Let me refresh here there we go so it's starting to show up uh so what this is going to do and this takes about 10 minutes 5 to 10 minutes for it to create and it's going to give us a rest in point so when this is done deploying we're going to come back and look at it I'm going to show you a couple of tricks you can do with it all right so our deployment is complete so now let's go play around with it let's see first thing I'd like to do is go and do a test and first thing we can probably do is just type in hello cuz this is the first thing you should do ah and we get an error so what do we do about this luckily there is a documentation page that covers this very error and it's not uncommon if you get this don't panic we can solve it relatively easily what we actually need to do is go to the resource Group where all of our Uh current Services live we're going to go to Identity and access management we're going to click on ADD and we're going to click on ADD R assignment what we need to look for is azure ml data and we'll see that we get Azure ml data scientist and then we're going to click next so at that point we're going to look for a managed identity we're going to select members and the managed identity that we're going to want to look for is going to be machine learning online endpoints so let's see if we can find it from here not there user assigned nope uh all identities search by name and what we need to look for is the online endpoint that we actually gave our uh Azure machine learning online inpoint which is vs vs subw let's go double check and make sure that's right so we can see it in the tab up here that is the name of our online inpoint so we're going to go back here click on select and we'll see that we have the AML prompt V subw click on next review and assign so this is going to take a couple of minutes so after we do that what's going to happen is and I'm going to include this link for this particular troubleshooting dock in the doc in the YouTube notes so you can actually pull this up problem is it's going to take about probably 5 minutes oh look it works we got access pretty quickly don't be surprised if you actually cuz typically in Azure identity World it may take several minutes for you to get this back but now we have uh a working you know what is included in perks plus but the nice thing is you have the ability to chat so you know that if you give your uh developer this endpoint the rest endpoint and this key and a sample code of python C or R you'll know they'll be able to get this working and uh basically get going with this all right so I've got another video I want to do later this will get you started you've got an online endpoint right now you can hand off to a developer you've got your prompt flow that you've created you've gone through everything all of it's working uh so now you can actually start going to town on the rag pattern using promp flow in Azure machine learning uh next couple of videos probably the next one I'm going to do is the evaluate the evaluate is really interesting because that gives you the ability to test your models to make sure they're behaving properly uh even even do some jailbreaks uh we'll talk about this in a future video uh and I'm also going to be doing another video where we talk about Azure AI studio uh which will be replacing prompt flow at some date in the near future so it doesn't mean that all this was in vain but we are going to be coming uh all of these tools that we see in prompt flow and Azure machine learning are going to be moved to the Azure AI studio so we'll be looking at that in a future video also anyway hope you enjoyed this uh thank you for your time today [Music] w\n"
     ]
    }
   ],
   "source": [
    "video_id = \"t73rFjUNY8823\"  # Example video ID\n",
    "transcript = fetch_transcript(video_id)\n",
    "print(\"\\nFinal Transcript:\\n\", transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio downloaded successfully: audio.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'audio.mp4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_audio(\"t73rFjUNY88\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nodefy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
